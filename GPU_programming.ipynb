{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "history_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rcpsousa/Ioslides_css/blob/master/GPU_programming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GPU programming. A starter.\n",
        "This exercise introduces GPU programming using cuda-c. We will start by installing pycuda. After that, we define some magic, which helps you work with your kernel more easily. Then, a short and easy example will be given. Next, we'll show you an example using Pytorch.\n",
        "\n",
        "Let's examine pycuda, a program that is not installed in Colab in the first example. Installing it is the first step."
      ],
      "metadata": {
        "id": "JFdH5Es4nCWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda\n",
        "import pycuda.driver as cuda"
      ],
      "metadata": {
        "id": "RGyHm_MIxFCH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2516292-8143-46da-8ab2-5b5fd80c48f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2022.2.2.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2023.1-py2.py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.4.4)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.6.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.3)\n",
            "Building wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2022.2.2-cp310-cp310-linux_x86_64.whl size=661975 sha256=bbd6fc2afc7297c028b09b95ae0c9e74956b0b00239fd72714a70b5706a63d1a\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/7b/06/82a395a243fce00035dea9914d92bbef0013401497d849f8bc\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.2.4 pycuda-2022.2.2 pytools-2023.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some wizardry\n",
        "A little magic was thrown in to make it easier to work with the examples. Don't worry, you don't have to understand it, but you can look at it if you want. To me, this kind of magic is fun. After all, coding can be fun and creative."
      ],
      "metadata": {
        "id": "_vvzSs413OaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.magic import (register_line_magic, register_cell_magic,\n",
        "                                register_line_cell_magic)\n",
        "from IPython.core.display import display_javascript\n",
        "\n",
        "from pycuda.compiler import SourceModule\n",
        "import pycuda.autoinit\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@register_cell_magic\n",
        "def CudaKernel(line, cell):\n",
        "  # p : regular expression for extracting the name of the kernel from the cuda code\n",
        "  p = re.compile('__global__\\s+(void|int|float|double|char)\\s+([a-zA-Z_]+([0-9_]*[a-zA-Z_]*)*)')\n",
        "  # cell keeps the cuda-c source code (the content of the cell). With SourceModule we load it\n",
        "  mod = SourceModule(cell)\n",
        "  # now we use the regular expression p for finding the kernel names.\n",
        "  M = p.findall(cell)\n",
        "  # Each kernel is added to the global namespace with its own name.\n",
        "  # With mod.get_function, we retreive the function.\n",
        "  for m in M:\n",
        "    globals()[m[1]] = mod.get_function(m[1])\n",
        "    print(f\"function {m[1]} created.\")\n",
        "\n",
        "js = \"IPython.CodeCell.options_default.highlight_modes['magic_text/x-csrc'] = {'reg':[/^%%CudaKernel/]};\"\n",
        "display_javascript(js, raw=True)"
      ],
      "metadata": {
        "id": "_EmyBGDd29iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CUDA\n",
        "\n",
        "With this CudaKernel Magic, we can create a simple program, which doubles the content of a 32 by 32 array:"
      ],
      "metadata": {
        "id": "t-0O_xswHRJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%CudaKernel\n",
        "__global__ void doublify(float *a) {\n",
        "  int idx = threadIdx.x + threadIdx.y*32;\n",
        "  a[idx] *= 2;\n",
        "}\n"
      ],
      "metadata": {
        "id": "WTWJKyrvz4xI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can think of Cuda-C as a dialect of C. Multidimensional arrays are one-dimensional, and a pointer to that array is passed to the function. Furthermore, there are some important things to note. We see that, despite the program running on a matrix, it is only working with one element of the array: a[idx]. To run this code, 32 x 32 = 1024 cores are allocated. ThreadIdx.x, threadIdx.y tells us which thread we're using and, therefore, which node to process. These aren't the only variables we have. Each thread is identified by a blockId (with its x, y, and z components) and a threadId (with its x, y, and z components). The variable blockSize (with its x, y, and z components) tells a thread how many threads are in a block.\n",
        "\n",
        "We'll see this later in the example. Let's run this program for now. We'll need to create a 32 by 32 matrix and copy it to the GPU:"
      ],
      "metadata": {
        "id": "LCbnOVAlM3S8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a random 32 x 32 matrix of type float32\n",
        "a = np.random.randn(32,32).astype(np.float32)\n",
        "\n",
        "# allocate memory on the GPU\n",
        "a_gpu = cuda.mem_alloc(a.nbytes)\n",
        "# copy the array to the gpu using the \"memcpy host to device\" (mem_htod) function\n",
        "cuda.memcpy_htod(a_gpu,a) # note that the first parameter is the destination and the second the origin."
      ],
      "metadata": {
        "id": "SQtNMsMsypCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that all the data is on the GPU, we can run the kernel. The block has to be 32 by 32 threads. You do that with the block-parameter (32 x 32 x 1). A pointer to the array is passed and computation can start. The kernel will process the data and the results will be stored in the same array."
      ],
      "metadata": {
        "id": "M1g9SUarWkEW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eZ68b2B6NxwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doublify(a_gpu, block=(32,32,1))"
      ],
      "metadata": {
        "id": "sNG61seDxzAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Afterwards, you can copy the data back to the CPU. We need an array to hold the results and copy the data from the GPU to the CPU using memcpy_dtoh (device to host). In our case, the array should have the same size as the original array. Finally, we need to free the memory allocated to the GPU. Then, we can use the results from the CPU array."
      ],
      "metadata": {
        "id": "7--ioM2uXsDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create an array with the same size as the input array\n",
        "a_doubled = np.empty_like(a)\n",
        "# copy the data from device to host\n",
        "cuda.memcpy_dtoh(a_doubled, a_gpu) # note that the first parameter is the destination and the second the origin.\n",
        "# Free the memory of the GPU\n",
        "a_gpu.free()\n",
        "\n",
        "print(a_doubled)"
      ],
      "metadata": {
        "id": "H49hSXWtyA0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**That's it. Our first CUDA program!!!**"
      ],
      "metadata": {
        "id": "F0s-hsGTZIyz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8I9_YLvcH4Og"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of cores on this card is defined as follows. First we look at the amount of multiprocessors. Each multiprocessor consists of a certain number of cores, determined by its version. For instance, a compute capability of 7.5 means 64 cores per multiprocessor. So that would mean that our GPU has 40 times 64 is 2560 cores."
      ],
      "metadata": {
        "id": "EbAoJwGfrg01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def ConvertSMVer2Cores(major, minor):\n",
        "    # Returns the number of CUDA cores per multiprocessor for a given\n",
        "    # Compute Capability version. There is no way to retrieve that via\n",
        "    # the API, so it needs to be hard-coded.\n",
        "    # See _ConvertSMVer2Cores in helper_cuda.h in NVIDIA's CUDA Samples.\n",
        "    return {(1, 0): 8,    # Tesla\n",
        "            (1, 1): 8,\n",
        "            (1, 2): 8,\n",
        "            (1, 3): 8,\n",
        "            (2, 0): 32,   # Fermi\n",
        "            (2, 1): 48,\n",
        "            (3, 0): 192,  # Kepler\n",
        "            (3, 2): 192,\n",
        "            (3, 5): 192,\n",
        "            (3, 7): 192,\n",
        "            (5, 0): 128,  # Maxwell\n",
        "            (5, 2): 128,\n",
        "            (5, 3): 128,\n",
        "            (6, 0): 64,   # Pascal\n",
        "            (6, 1): 128,\n",
        "            (6, 2): 128,\n",
        "            (7, 0): 64,   # Volta\n",
        "            (7, 2): 64,\n",
        "            (7, 5): 64,   # Turing\n",
        "            (8, 0): 64,   # Ampere\n",
        "            (8, 6): 64,\n",
        "            }.get((major, minor), 0)\n",
        "\n",
        "device=cuda.Device(0)\n",
        "attrs=device.get_attributes()\n",
        "#print(f\"warp size: {attrs[pycuda._driver.device_attribute.WARP_SIZE]}\")\n",
        "print(f\"multiprocessor count: {attrs[pycuda._driver.device_attribute.MULTIPROCESSOR_COUNT]}\")\n",
        "major = attrs[pycuda._driver.device_attribute.COMPUTE_CAPABILITY_MAJOR]\n",
        "minor = attrs[pycuda._driver.device_attribute.COMPUTE_CAPABILITY_MINOR]\n",
        "print(f\"compute capability: {major}.{minor}\")\n",
        "corespermultiprocessor = ConvertSMVer2Cores(major, minor)\n",
        "print(f\"Number of cores per multiprocessor: {corespermultiprocessor}\")\n",
        "print(f\"Total number of cores: {corespermultiprocessor * attrs[pycuda._driver.device_attribute.MULTIPROCESSOR_COUNT] }\")"
      ],
      "metadata": {
        "id": "ezHulNqNz6CG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mDD4UwrnA370"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%CudaKernel\n",
        "__global__ void doublify(float *a) {\n",
        "  int idx = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "  a[idx] *= 2;\n",
        "}\n"
      ],
      "metadata": {
        "id": "S6kTZbD30R-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a random 32 x 32 matrix of type float32\n",
        "a = np.random.randn(1024,1024).astype(np.float32)\n",
        "\n",
        "# allocate memory on the GPU\n",
        "a_gpu = cuda.mem_alloc(a.nbytes)\n",
        "# copy the array to the gpu using the \"memcpy host to device\" (mem_htod) function\n",
        "cuda.memcpy_htod(a_gpu,a) # note that the first parameter is the destination and the second the origin.\n",
        "\n",
        "doublify(a_gpu, block=(1024,1,1), grid=(1024,1,1))\n",
        "\n",
        "# create an array with the same size as the input array\n",
        "a_doubled = np.empty_like(a)\n",
        "# copy the data from device to host\n",
        "cuda.memcpy_dtoh(a_doubled, a_gpu) # note that the first parameter is the destination and the second the origin.\n",
        "# Free the memory of the GPU\n",
        "a_gpu.free()\n",
        "print(a, a.shape)\n",
        "print(a_doubled, a_doubled.shape)\n"
      ],
      "metadata": {
        "id": "iuEsfKvt0x70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 1\n",
        "Create a function triplify to triple the value of __a__. Hint: You can just copy and paste the code from above to get it up and running."
      ],
      "metadata": {
        "id": "49NKJzlV6eTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# insert your code her"
      ],
      "metadata": {
        "id": "LMLpdOHm62YN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## find the maximum of an array\n",
        "Some problems are hard to parallelize. One of these problems is the maximum of an array.\n",
        "\n",
        "To do this, we can use a divide and conquer approach:\n",
        "1. let a be the array with N elements\n",
        "2. let n <= N\n",
        "3. Reduce the array of n elements to n/2 elements by taking the maximum of  the i-th element and the (i+n/2)th element\n",
        "4. n <= n/2\n",
        "5. if n = 1/2 => stop\n",
        "6. goto 2\n",
        "\n",
        "In cuda-c this looks like this:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NzJR0UvO59GD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%CudaKernel\n",
        "__global__ void max_iter(float *a, int *N)\n",
        "{\n",
        "\n",
        "    for (int n=((*N)>>1); n>0; n>>=1)\n",
        "    {\n",
        "        int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "        if (idx < n)\n",
        "        {\n",
        "          int b = (a[idx] < a[idx + n]);\n",
        "          a[idx] = a[idx + n*b];\n",
        "        }\n",
        "    }\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "qCSz8Xgn7Gcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Rbzfq7bFWKFD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let us test it."
      ],
      "metadata": {
        "id": "RtSAkWQDONDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define the array and upload it to the gpu\n",
        "a = np.random.randn(2048).astype(\"float32\")\n",
        "a_gpu = cuda.mem_alloc(a.nbytes)\n",
        "cuda.memcpy_htod(a_gpu, a)\n",
        "#define a variable holding the length of the array and copy it to the gpu\n",
        "N = np.array([a.shape[0]], dtype=\"int\")\n",
        "N_gpu = cuda.mem_alloc(N.nbytes)\n",
        "cuda.memcpy_htod(N_gpu, N)\n",
        "#call the max_iter kernel with half of the number of cores\n",
        "max_iter(a_gpu, N_gpu, block=(a.shape[0]//2,1,1))\n",
        "#define the return matrix and use it. We only need the first element,\n",
        "#so we define an ndarray with one element.\n",
        "a_max = np.zeros((1,), dtype = \"float32\")\n",
        "cuda.memcpy_dtoh(a_max, a_gpu)\n",
        "print(f\"{a_max[0]} == {np.max(a)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "FUajf_TJ9dzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 2\n",
        "Create a kernel to find:\n",
        "- the minimum of an array, or\n",
        "- the average of an array"
      ],
      "metadata": {
        "id": "v_SVV5hrWanQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%CudaKernel\n",
        "// insert your cuda-c code here"
      ],
      "metadata": {
        "id": "Wjf1hdFTXlkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## insert your test code here"
      ],
      "metadata": {
        "id": "xCFM-P2TX26v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pyTorch\n",
        "For the remainder we will look at pyTorch. Torch is known to be used for training neural networks, but can also be used for other problems. Here, we will implement the 'doublify' example in pytorch. First we need to import torch:"
      ],
      "metadata": {
        "id": "J1Ua9M3U7XXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "9joT75pH7WQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we check if the GPU is available and we store its reference to device. We actually know that already, since we used it for the CUDA example."
      ],
      "metadata": {
        "id": "kFPfowaN8g8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  dev = \"cuda:0\"\n",
        "else:\n",
        "  dev = \"cpu\"\n",
        "device = torch.device(dev)\n",
        "dev"
      ],
      "metadata": {
        "id": "U0hrkAro8oeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the fun can begin. We first create a torch tensor:"
      ],
      "metadata": {
        "id": "PleujgrS8BsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.random.randn(1000, 1000)\n",
        "a_torch = torch.tensor(a)"
      ],
      "metadata": {
        "id": "QsFs9X637erO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 3\n",
        "To execute the tensor on a GPU, we have to create it on the GPU. This is done by specifying the device with the line `device=<device>`. Please change the code in the next block to use the device `dev`"
      ],
      "metadata": {
        "id": "atO-o38uQvyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.random.randn(1000, 1000, ###insert code here###)\n",
        "a_torch = torch.tensor(a)"
      ],
      "metadata": {
        "id": "tSipM0jBRI1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And like in the first example we double it. Note how easy this functions in pytorch."
      ],
      "metadata": {
        "id": "1D50eXBVYK5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "2*a_torch"
      ],
      "metadata": {
        "id": "vs2eGC8u8NHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In another example we will try to estimate the number pi with a monte carlo simulation. Therefore, we plot $N$ points on a square of 2 by 2. Then we draw a unity circle in the square and count the number of dots that fall within the circle. ![pi.png](data:image/png;base64,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)\n",
        "\n",
        "The probability that a point is inside the cirle is equal to $\\frac \\pi 4$, so we can estimate $\\pi$ by calculating the fraction of points which are inside the circle and multiply it with 4.\n",
        "\n",
        "The version in numpy:"
      ],
      "metadata": {
        "id": "8hUcKIvvhX9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "N = 100000000;\n",
        "tic = time();\n",
        "x = np.random.rand(N,2)*2-1\n",
        "y = ((x[:,0]**2+x[:,1]**2)<=1)\n",
        "n = y.sum()\n",
        "toc = time()\n",
        "print(f\"Pi is approximately {4* n/N} (in {round(1000*(toc-tic))} ms.)\" )"
      ],
      "metadata": {
        "id": "asZurFWgfUYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 4\n",
        "The following cell shows the code for torch, but there is one mistake in the code, which makes that it does not work faster. Find the mistake and correct it."
      ],
      "metadata": {
        "id": "y5cIHLiMaxrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tic = time()\n",
        "x = torch.rand(N,2)*2-1\n",
        "y = ((x[:,0]**2+x[:,1]**2)<=1)\n",
        "n = y.sum()\n",
        "toc = time()\n",
        "print(f\"Pi is approximately {4* n/N} (in {round(1000*(toc-tic))} ms.)\" )"
      ],
      "metadata": {
        "id": "sNJUfFXqRqIe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}